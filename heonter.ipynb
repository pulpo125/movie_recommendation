{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow2로 MF 구현\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>879</td>\n",
       "      <td>475</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>715</td>\n",
       "      <td>203</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>275</td>\n",
       "      <td>1089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>12</td>\n",
       "      <td>224</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>11</td>\n",
       "      <td>202</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0          195       241     3.0\n",
       "1          185       301     3.0\n",
       "2           21       376     1.0\n",
       "3          243        50     2.0\n",
       "4          165       345     1.0\n",
       "...        ...       ...     ...\n",
       "99995      879       475     3.0\n",
       "99996      715       203     5.0\n",
       "99997      275      1089     1.0\n",
       "99998       12       224     2.0\n",
       "99999       11       202     3.0\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings=pd.read_csv('data/ratings.csv')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=pd.read_csv('data/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv('data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   user_id   100000 non-null  int64  \n",
      " 1   movie_id  100000 non-null  int64  \n",
      " 2   rating    100000 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, holdout_fraction=0.1):\n",
    "  \"\"\"Splits a DataFrame into training and test sets.\n",
    "  Args:\n",
    "    df: a dataframe.\n",
    "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
    "  Returns:\n",
    "    train: dataframe for training\n",
    "    test: dataframe for testing\n",
    "  \"\"\"\n",
    "  test = df.sample(frac=holdout_fraction, replace=False)\n",
    "  train = df[~df.index.isin(test.index)]\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90000, 3), (10000, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['user_id'] = ratings['user_id'].astype(int)\n",
    "ratings['movie_id'] = ratings['movie_id'].astype(int)\n",
    "\n",
    "train_ratings, test_ratings = split_dataframe(ratings)\n",
    "train_ratings.shape, test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens=pd.read_csv('data/movielens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>all_genres</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Kolya%20(1996)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Men in Black (1997)</td>\n",
       "      <td>04-Jul-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Men+in+Black+...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Action-Adventure-Comedy-Sci-Fi</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Truth About Cats &amp; Dogs, The (1996)</td>\n",
       "      <td>26-Apr-1996</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Truth%20About...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy-Romance</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Birdcage, The (1996)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Birdcage,%20T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195</td>\n",
       "      <td>381</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Adventures of Priscilla, Queen of the Desert, ...</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Adventures%20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy-Drama</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>872</td>\n",
       "      <td>312</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?imdb-title-12...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Action-Drama-Romance</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>872</td>\n",
       "      <td>325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>G.I. Jane (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?G%2EI%2E+Jane...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Action-Drama-War</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>872</td>\n",
       "      <td>347</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Desperate Measures (1998)</td>\n",
       "      <td>30-Jan-1998</td>\n",
       "      <td>http://us.imdb.com/Title?Desperate+Measures+(1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Crime-Drama-Thriller</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>872</td>\n",
       "      <td>357</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Spawn (1997)</td>\n",
       "      <td>01-Aug-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Spawn+(1997/I)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Action-Adventure-Sci-Fi-Thriller</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>872</td>\n",
       "      <td>341</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Man Who Knew Too Little, The (1997)</td>\n",
       "      <td>01-Jan-1997</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Man+Who+Knew+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy-Mystery</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  \\\n",
       "0          195       241     3.0   \n",
       "1          195       256     2.0   \n",
       "2          195       110     4.0   \n",
       "3          195        24     4.0   \n",
       "4          195       381     4.0   \n",
       "...        ...       ...     ...   \n",
       "99995      872       312     5.0   \n",
       "99996      872       325     4.0   \n",
       "99997      872       347     3.0   \n",
       "99998      872       357     2.0   \n",
       "99999      872       341     4.0   \n",
       "\n",
       "                                                   title release_date  \\\n",
       "0                                           Kolya (1996)  24-Jan-1997   \n",
       "1                                    Men in Black (1997)  04-Jul-1997   \n",
       "2                    Truth About Cats & Dogs, The (1996)  26-Apr-1996   \n",
       "3                                   Birdcage, The (1996)  08-Mar-1996   \n",
       "4      Adventures of Priscilla, Queen of the Desert, ...  01-Jan-1994   \n",
       "...                                                  ...          ...   \n",
       "99995                                     Titanic (1997)  01-Jan-1997   \n",
       "99996                                   G.I. Jane (1997)  01-Jan-1997   \n",
       "99997                          Desperate Measures (1998)  30-Jan-1998   \n",
       "99998                                       Spawn (1997)  01-Aug-1997   \n",
       "99999                Man Who Knew Too Little, The (1997)  01-Jan-1997   \n",
       "\n",
       "                                                imdb_url  genre_unknown  \\\n",
       "0        http://us.imdb.com/M/title-exact?Kolya%20(1996)              0   \n",
       "1      http://us.imdb.com/M/title-exact?Men+in+Black+...              0   \n",
       "2      http://us.imdb.com/M/title-exact?Truth%20About...              0   \n",
       "3      http://us.imdb.com/M/title-exact?Birdcage,%20T...              0   \n",
       "4      http://us.imdb.com/M/title-exact?Adventures%20...              0   \n",
       "...                                                  ...            ...   \n",
       "99995  http://us.imdb.com/M/title-exact?imdb-title-12...              0   \n",
       "99996  http://us.imdb.com/M/title-exact?G%2EI%2E+Jane...              0   \n",
       "99997  http://us.imdb.com/Title?Desperate+Measures+(1...              0   \n",
       "99998    http://us.imdb.com/M/title-exact?Spawn+(1997/I)              0   \n",
       "99999  http://us.imdb.com/M/title-exact?Man+Who+Knew+...              0   \n",
       "\n",
       "       Action  Adventure  Animation  ...  Mystery  Romance  Sci-Fi  Thriller  \\\n",
       "0           0          0          0  ...        0        0       0         0   \n",
       "1           1          1          0  ...        0        0       1         0   \n",
       "2           0          0          0  ...        0        1       0         0   \n",
       "3           0          0          0  ...        0        0       0         0   \n",
       "4           0          0          0  ...        0        0       0         0   \n",
       "...       ...        ...        ...  ...      ...      ...     ...       ...   \n",
       "99995       1          0          0  ...        0        1       0         0   \n",
       "99996       1          0          0  ...        0        0       0         0   \n",
       "99997       0          0          0  ...        0        0       0         1   \n",
       "99998       1          1          0  ...        0        0       1         1   \n",
       "99999       0          0          0  ...        1        0       0         0   \n",
       "\n",
       "       War  Western                        all_genres  age  sex     occupation  \n",
       "0        0        0                            Comedy   49    M         writer  \n",
       "1        0        0    Action-Adventure-Comedy-Sci-Fi   49    M         writer  \n",
       "2        0        0                    Comedy-Romance   49    M         writer  \n",
       "3        0        0                            Comedy   49    M         writer  \n",
       "4        0        0                      Comedy-Drama   49    M         writer  \n",
       "...    ...      ...                               ...  ...  ...            ...  \n",
       "99995    0        0              Action-Drama-Romance   48    F  administrator  \n",
       "99996    1        0                  Action-Drama-War   48    F  administrator  \n",
       "99997    0        0              Crime-Drama-Thriller   48    F  administrator  \n",
       "99998    0        0  Action-Adventure-Sci-Fi-Thriller   48    F  administrator  \n",
       "99999    0        0                    Comedy-Mystery   48    F  administrator  \n",
       "\n",
       "[100000 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors = 30 # user와 movie embedding의 차원수\n",
    "\n",
    "user_input = Input(shape=[1], name='user')\n",
    "movie_input = Input(shape=[1], name='movie')\n",
    "\n",
    "user_embedding = Embedding(input_dim=users.shape[0] # 943\n",
    "                           , output_dim = n_latent_factors # 30\n",
    "                           , name='user_embedding'\n",
    "                           )(user_input)\n",
    "\n",
    "movie_embedding = Embedding(input_dim=movies.shape[0] # 1682\n",
    "                           , output_dim = n_latent_factors # 30\n",
    "                           , name='movie_embedding'\n",
    "                           )(movie_input)\n",
    "\n",
    "user_vec = Flatten(name='flatten_users')(user_embedding) # 1차원 배열로 변환\n",
    "movie_vec = Flatten(name='flatten_movies')(movie_embedding) # 1차원 배열로 변환\n",
    "\n",
    "product = dot([movie_vec, user_vec], axes=1) # 평점\n",
    "model = Model(inputs=[user_input, movie_input], outputs=product) # user와 movie가 주어졌을 때, 평점을 예측하는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " movie (InputLayer)             [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " user (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding)    (None, 1, 30)        50460       ['movie[0][0]']                  \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)     (None, 1, 30)        28290       ['user[0][0]']                   \n",
      "                                                                                                  \n",
      " flatten_movies (Flatten)       (None, 30)           0           ['movie_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_users (Flatten)        (None, 30)           0           ['user_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['flatten_movies[0][0]',         \n",
      "                                                                  'flatten_users[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78,750\n",
      "Trainable params: 78,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.7115 - val_loss: 13.8682\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.7107 - val_loss: 13.8682\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.7098 - val_loss: 13.8682\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.7089 - val_loss: 13.8681\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.7079 - val_loss: 13.8679\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.7068 - val_loss: 13.8675\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.7057 - val_loss: 13.8670\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.7043 - val_loss: 13.8664\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.7029 - val_loss: 13.8655\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.7012 - val_loss: 13.8644\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6993 - val_loss: 13.8631\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6972 - val_loss: 13.8615\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.6949 - val_loss: 13.8596\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.6923 - val_loss: 13.8573\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.6894 - val_loss: 13.8548\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6862 - val_loss: 13.8518\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.6826 - val_loss: 13.8485\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.6787 - val_loss: 13.8448\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6744 - val_loss: 13.8406\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6696 - val_loss: 13.8360\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6644 - val_loss: 13.8309\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6588 - val_loss: 13.8252\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6527 - val_loss: 13.8191\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.6460 - val_loss: 13.8124\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6388 - val_loss: 13.8051\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6311 - val_loss: 13.7973\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6228 - val_loss: 13.7888\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6139 - val_loss: 13.7797\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6043 - val_loss: 13.7699\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5941 - val_loss: 13.7595\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.5833 - val_loss: 13.7483\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5718 - val_loss: 13.7364\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5595 - val_loss: 13.7238\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5465 - val_loss: 13.7104\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5328 - val_loss: 13.6962\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5183 - val_loss: 13.6812\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5031 - val_loss: 13.6654\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.4870 - val_loss: 13.6488\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.4701 - val_loss: 13.6313\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.4523 - val_loss: 13.6129\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.4337 - val_loss: 13.5936\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.4142 - val_loss: 13.5734\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.3938 - val_loss: 13.5523\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.3725 - val_loss: 13.5302\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.3503 - val_loss: 13.5072\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.3272 - val_loss: 13.4832\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.3031 - val_loss: 13.4582\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.2780 - val_loss: 13.4323\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.2519 - val_loss: 13.4053\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.2249 - val_loss: 13.3773\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.1969 - val_loss: 13.3483\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.1679 - val_loss: 13.3183\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.1379 - val_loss: 13.2873\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.1068 - val_loss: 13.2552\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.0748 - val_loss: 13.2221\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.0417 - val_loss: 13.1879\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.0075 - val_loss: 13.1526\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.9724 - val_loss: 13.1163\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.9362 - val_loss: 13.0790\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.8989 - val_loss: 13.0406\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.8606 - val_loss: 13.0011\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.8213 - val_loss: 12.9606\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.7809 - val_loss: 12.9190\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.7395 - val_loss: 12.8764\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.6970 - val_loss: 12.8327\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.6535 - val_loss: 12.7880\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.6090 - val_loss: 12.7422\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.5634 - val_loss: 12.6953\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.5168 - val_loss: 12.6475\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.4691 - val_loss: 12.5986\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.4205 - val_loss: 12.5486\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.3708 - val_loss: 12.4977\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.3201 - val_loss: 12.4457\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.2685 - val_loss: 12.3928\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.2158 - val_loss: 12.3388\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.1621 - val_loss: 12.2839\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.1075 - val_loss: 12.2279\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.0519 - val_loss: 12.1710\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.9954 - val_loss: 12.1132\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.9379 - val_loss: 12.0544\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.8794 - val_loss: 11.9947\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.8200 - val_loss: 11.9340\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.7598 - val_loss: 11.8724\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.6986 - val_loss: 11.8099\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.6365 - val_loss: 11.7466\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.5735 - val_loss: 11.6823\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.5097 - val_loss: 11.6172\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.4450 - val_loss: 11.5513\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.3795 - val_loss: 11.4845\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.3132 - val_loss: 11.4169\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.2460 - val_loss: 11.3485\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.1781 - val_loss: 11.2793\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1094 - val_loss: 11.2093\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.0399 - val_loss: 11.1386\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.9696 - val_loss: 11.0671\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.8986 - val_loss: 10.9949\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.8269 - val_loss: 10.9220\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.7545 - val_loss: 10.8484\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.6814 - val_loss: 10.7741\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.6077 - val_loss: 10.6991\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.5333 - val_loss: 10.6235\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.4582 - val_loss: 10.5473\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.3826 - val_loss: 10.4705\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.3063 - val_loss: 10.3931\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.2295 - val_loss: 10.3151\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.1521 - val_loss: 10.2365\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.0741 - val_loss: 10.1574\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.9956 - val_loss: 10.0778\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.9166 - val_loss: 9.9978\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.8372 - val_loss: 9.9172\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.7572 - val_loss: 9.8362\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.6768 - val_loss: 9.7547\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.5960 - val_loss: 9.6728\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.5147 - val_loss: 9.5905\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.4331 - val_loss: 9.5078\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.3511 - val_loss: 9.4248\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.2687 - val_loss: 9.3414\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.1860 - val_loss: 9.2577\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.1030 - val_loss: 9.1737\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.0197 - val_loss: 9.0894\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9361 - val_loss: 9.0049\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.8522 - val_loss: 8.9201\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.7681 - val_loss: 8.8351\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.6838 - val_loss: 8.7499\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.5993 - val_loss: 8.6645\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.5147 - val_loss: 8.5789\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.4298 - val_loss: 8.4932\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.3449 - val_loss: 8.4074\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.2598 - val_loss: 8.3215\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.1746 - val_loss: 8.2355\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.0894 - val_loss: 8.1495\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.0041 - val_loss: 8.0634\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.9188 - val_loss: 7.9773\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.8334 - val_loss: 7.8912\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.7481 - val_loss: 7.8051\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.6628 - val_loss: 7.7190\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.5775 - val_loss: 7.6330\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.4923 - val_loss: 7.5471\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.4072 - val_loss: 7.4613\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.3222 - val_loss: 7.3756\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.2373 - val_loss: 7.2901\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.1525 - val_loss: 7.2047\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.0680 - val_loss: 7.1195\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.9836 - val_loss: 7.0345\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.8994 - val_loss: 6.9497\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.8154 - val_loss: 6.8651\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.7316 - val_loss: 6.7808\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.6482 - val_loss: 6.6968\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.5649 - val_loss: 6.6130\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4820 - val_loss: 6.5296\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.3994 - val_loss: 6.4465\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.3171 - val_loss: 6.3637\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.2352 - val_loss: 6.2813\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.1537 - val_loss: 6.1993\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0725 - val_loss: 6.1176\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9917 - val_loss: 6.0364\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9113 - val_loss: 5.9556\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.8314 - val_loss: 5.8753\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.7519 - val_loss: 5.7954\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.6728 - val_loss: 5.7160\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.5943 - val_loss: 5.6371\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.5162 - val_loss: 5.5587\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.4387 - val_loss: 5.4808\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.3616 - val_loss: 5.4034\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.2851 - val_loss: 5.3266\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.2092 - val_loss: 5.2504\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.1338 - val_loss: 5.1747\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.0590 - val_loss: 5.0997\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.9848 - val_loss: 5.0252\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.9112 - val_loss: 4.9514\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.8382 - val_loss: 4.8782\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.7658 - val_loss: 4.8056\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.6941 - val_loss: 4.7337\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.6230 - val_loss: 4.6624\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.5526 - val_loss: 4.5919\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.4829 - val_loss: 4.5220\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.4138 - val_loss: 4.4528\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3454 - val_loss: 4.3843\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.2778 - val_loss: 4.3165\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.2108 - val_loss: 4.2494\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.1446 - val_loss: 4.1831\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.0791 - val_loss: 4.1175\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.0143 - val_loss: 4.0527\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.9503 - val_loss: 3.9886\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8870 - val_loss: 3.9252\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8245 - val_loss: 3.8627\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7627 - val_loss: 3.8009\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7017 - val_loss: 3.7399\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.6415 - val_loss: 3.6797\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.5821 - val_loss: 3.6202\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.5234 - val_loss: 3.5616\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4656 - val_loss: 3.5037\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4085 - val_loss: 3.4467\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3522 - val_loss: 3.3904\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.2967 - val_loss: 3.3350\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.2420 - val_loss: 3.2803\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1881 - val_loss: 3.2265\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1350 - val_loss: 3.1735\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0828 - val_loss: 3.1213\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0313 - val_loss: 3.0699\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9806 - val_loss: 3.0193\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9307 - val_loss: 2.9695\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.8817 - val_loss: 2.9206\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.8334 - val_loss: 2.8724\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7860 - val_loss: 2.8251\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7393 - val_loss: 2.7786\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6935 - val_loss: 2.7329\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6484 - val_loss: 2.6879\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6041 - val_loss: 2.6438\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5607 - val_loss: 2.6005\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5180 - val_loss: 2.5580\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4761 - val_loss: 2.5162\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4350 - val_loss: 2.4753\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3946 - val_loss: 2.4351\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3551 - val_loss: 2.3957\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3163 - val_loss: 2.3571\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2782 - val_loss: 2.3192\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2409 - val_loss: 2.2821\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2044 - val_loss: 2.2458\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1686 - val_loss: 2.2102\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1336 - val_loss: 2.1753\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0993 - val_loss: 2.1412\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0657 - val_loss: 2.1078\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0328 - val_loss: 2.0751\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0006 - val_loss: 2.0431\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9692 - val_loss: 2.0119\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9384 - val_loss: 1.9813\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9083 - val_loss: 1.9514\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8789 - val_loss: 1.9222\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8502 - val_loss: 1.8937\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8221 - val_loss: 1.8659\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7947 - val_loss: 1.8386\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7679 - val_loss: 1.8121\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7418 - val_loss: 1.7862\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7163 - val_loss: 1.7609\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6914 - val_loss: 1.7362\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6671 - val_loss: 1.7121\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6434 - val_loss: 1.6886\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6203 - val_loss: 1.6657\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5978 - val_loss: 1.6434\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5759 - val_loss: 1.6217\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5545 - val_loss: 1.6005\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5336 - val_loss: 1.5799\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5133 - val_loss: 1.5598\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4936 - val_loss: 1.5402\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4743 - val_loss: 1.5212\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4556 - val_loss: 1.5027\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4374 - val_loss: 1.4846\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4196 - val_loss: 1.4671\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4024 - val_loss: 1.4501\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3856 - val_loss: 1.4335\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3693 - val_loss: 1.4174\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3534 - val_loss: 1.4017\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3380 - val_loss: 1.3865\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3230 - val_loss: 1.3717\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3084 - val_loss: 1.3573\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2943 - val_loss: 1.3433\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2805 - val_loss: 1.3298\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2672 - val_loss: 1.3166\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2542 - val_loss: 1.3038\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2416 - val_loss: 1.2914\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2294 - val_loss: 1.2794\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2176 - val_loss: 1.2677\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2060 - val_loss: 1.2564\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1949 - val_loss: 1.2454\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1840 - val_loss: 1.2348\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1735 - val_loss: 1.2245\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1633 - val_loss: 1.2144\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1535 - val_loss: 1.2047\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1439 - val_loss: 1.1953\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1346 - val_loss: 1.1862\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1256 - val_loss: 1.1774\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1169 - val_loss: 1.1688\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1084 - val_loss: 1.1605\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1002 - val_loss: 1.1525\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0922 - val_loss: 1.1447\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0845 - val_loss: 1.1372\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0771 - val_loss: 1.1299\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0699 - val_loss: 1.1228\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0629 - val_loss: 1.1160\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0561 - val_loss: 1.1094\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0495 - val_loss: 1.1030\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0432 - val_loss: 1.0968\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0370 - val_loss: 1.0908\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0310 - val_loss: 1.0850\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0253 - val_loss: 1.0793\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0197 - val_loss: 1.0739\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0143 - val_loss: 1.0687\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0090 - val_loss: 1.0636\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0039 - val_loss: 1.0586\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9990 - val_loss: 1.0539\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9943 - val_loss: 1.0493\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9897 - val_loss: 1.0448\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9852 - val_loss: 1.0405\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9809 - val_loss: 1.0363\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9767 - val_loss: 1.0323\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9727 - val_loss: 1.0284\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9687 - val_loss: 1.0246\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9650 - val_loss: 1.0210\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9613 - val_loss: 1.0174\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9577 - val_loss: 1.0140\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9543 - val_loss: 1.0107\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9509 - val_loss: 1.0075\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9477 - val_loss: 1.0044\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9446 - val_loss: 1.0014\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9416 - val_loss: 0.9985\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9386 - val_loss: 0.9957\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9358 - val_loss: 0.9930\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9330 - val_loss: 0.9904\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9304 - val_loss: 0.9879\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9278 - val_loss: 0.9854\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9253 - val_loss: 0.9831\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9229 - val_loss: 0.9808\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9205 - val_loss: 0.9785\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9182 - val_loss: 0.9764\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9160 - val_loss: 0.9743\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9139 - val_loss: 0.9723\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9118 - val_loss: 0.9704\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9098 - val_loss: 0.9685\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9078 - val_loss: 0.9666\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9060 - val_loss: 0.9649\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9041 - val_loss: 0.9632\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9023 - val_loss: 0.9615\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9006 - val_loss: 0.9599\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8989 - val_loss: 0.9583\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8973 - val_loss: 0.9568\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8957 - val_loss: 0.9554\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8942 - val_loss: 0.9540\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8927 - val_loss: 0.9526\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8913 - val_loss: 0.9513\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8899 - val_loss: 0.9500\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8885 - val_loss: 0.9488\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8872 - val_loss: 0.9475\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8859 - val_loss: 0.9464\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8847 - val_loss: 0.9452\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8835 - val_loss: 0.9441\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8823 - val_loss: 0.9431\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8811 - val_loss: 0.9420\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8800 - val_loss: 0.9410\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8789 - val_loss: 0.9401\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8779 - val_loss: 0.9391\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8769 - val_loss: 0.9382\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8759 - val_loss: 0.9373\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8749 - val_loss: 0.9365\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8740 - val_loss: 0.9356\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8730 - val_loss: 0.9348\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8721 - val_loss: 0.9340\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8713 - val_loss: 0.9333\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8704 - val_loss: 0.9325\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8696 - val_loss: 0.9318\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8688 - val_loss: 0.9311\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8680 - val_loss: 0.9304\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8673 - val_loss: 0.9298\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8665 - val_loss: 0.9291\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8658 - val_loss: 0.9285\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8651 - val_loss: 0.9279\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8644 - val_loss: 0.9273\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8637 - val_loss: 0.9267\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8631 - val_loss: 0.9262\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8625 - val_loss: 0.9256\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8618 - val_loss: 0.9251\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8612 - val_loss: 0.9246\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8606 - val_loss: 0.9241\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8601 - val_loss: 0.9236\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8595 - val_loss: 0.9232\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8590 - val_loss: 0.9227\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8584 - val_loss: 0.9223\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8579 - val_loss: 0.9218\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8574 - val_loss: 0.9214\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8569 - val_loss: 0.9210\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8564 - val_loss: 0.9206\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8559 - val_loss: 0.9202\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8555 - val_loss: 0.9198\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8550 - val_loss: 0.9195\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8546 - val_loss: 0.9191\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8541 - val_loss: 0.9187\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8537 - val_loss: 0.9184\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8533 - val_loss: 0.9181\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8529 - val_loss: 0.9177\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8525 - val_loss: 0.9174\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8521 - val_loss: 0.9171\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8517 - val_loss: 0.9168\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8514 - val_loss: 0.9165\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8510 - val_loss: 0.9162\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8506 - val_loss: 0.9160\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8503 - val_loss: 0.9157\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8500 - val_loss: 0.9154\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8496 - val_loss: 0.9152\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8493 - val_loss: 0.9149\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8490 - val_loss: 0.9147\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8487 - val_loss: 0.9144\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8484 - val_loss: 0.9142\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8481 - val_loss: 0.9140\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8478 - val_loss: 0.9138\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8475 - val_loss: 0.9136\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8472 - val_loss: 0.9133\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8469 - val_loss: 0.9131\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8467 - val_loss: 0.9129\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8464 - val_loss: 0.9127\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8461 - val_loss: 0.9125\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8459 - val_loss: 0.9124\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8456 - val_loss: 0.9122\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8454 - val_loss: 0.9120\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8452 - val_loss: 0.9118\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8449 - val_loss: 0.9117\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8447 - val_loss: 0.9115\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8445 - val_loss: 0.9113\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8442 - val_loss: 0.9112\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8440 - val_loss: 0.9110\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8438 - val_loss: 0.9109\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8436 - val_loss: 0.9107\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8434 - val_loss: 0.9106\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8432 - val_loss: 0.9104\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8430 - val_loss: 0.9103\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8428 - val_loss: 0.9102\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8426 - val_loss: 0.9100\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8424 - val_loss: 0.9099\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8422 - val_loss: 0.9098\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8421 - val_loss: 0.9096\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8419 - val_loss: 0.9095\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8417 - val_loss: 0.9094\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8415 - val_loss: 0.9093\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8414 - val_loss: 0.9092\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8412 - val_loss: 0.9091\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8411 - val_loss: 0.9090\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8409 - val_loss: 0.9089\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8407 - val_loss: 0.9087\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8406 - val_loss: 0.9086\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8404 - val_loss: 0.9085\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8403 - val_loss: 0.9085\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8401 - val_loss: 0.9084\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8400 - val_loss: 0.9083\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8398 - val_loss: 0.9082\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8397 - val_loss: 0.9081\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8396 - val_loss: 0.9080\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8394 - val_loss: 0.9079\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8393 - val_loss: 0.9078\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8392 - val_loss: 0.9077\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8390 - val_loss: 0.9077\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8389 - val_loss: 0.9076\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8388 - val_loss: 0.9075\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8387 - val_loss: 0.9074\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8386 - val_loss: 0.9074\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8384 - val_loss: 0.9073\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8383 - val_loss: 0.9072\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8382 - val_loss: 0.9072\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8381 - val_loss: 0.9071\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8380 - val_loss: 0.9070\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8379 - val_loss: 0.9070\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8378 - val_loss: 0.9069\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8377 - val_loss: 0.9068\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8376 - val_loss: 0.9068\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8375 - val_loss: 0.9067\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8374 - val_loss: 0.9067\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8373 - val_loss: 0.9066\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8372 - val_loss: 0.9065\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8371 - val_loss: 0.9065\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8370 - val_loss: 0.9064\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8369 - val_loss: 0.9064\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8368 - val_loss: 0.9063\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8367 - val_loss: 0.9063\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8366 - val_loss: 0.9062\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8365 - val_loss: 0.9062\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8364 - val_loss: 0.9061\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8363 - val_loss: 0.9061\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8362 - val_loss: 0.9060\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8362 - val_loss: 0.9060\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8361 - val_loss: 0.9059\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8360 - val_loss: 0.9059\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8359 - val_loss: 0.9059\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8358 - val_loss: 0.9058\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8358 - val_loss: 0.9058\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8357 - val_loss: 0.9057\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8356 - val_loss: 0.9057\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8355 - val_loss: 0.9057\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8354 - val_loss: 0.9056\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8354 - val_loss: 0.9056\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8353 - val_loss: 0.9055\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8352 - val_loss: 0.9055\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8352 - val_loss: 0.9055\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8351 - val_loss: 0.9054\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8350 - val_loss: 0.9054\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8349 - val_loss: 0.9054\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8349 - val_loss: 0.9053\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8348 - val_loss: 0.9053\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8347 - val_loss: 0.9053\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8347 - val_loss: 0.9052\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8346 - val_loss: 0.9052\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8345 - val_loss: 0.9052\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8345 - val_loss: 0.9052\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8344 - val_loss: 0.9051\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8344 - val_loss: 0.9051\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8343 - val_loss: 0.9051\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8342 - val_loss: 0.9050\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8342 - val_loss: 0.9050\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8341 - val_loss: 0.9050\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8341 - val_loss: 0.9050\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8340 - val_loss: 0.9049\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8339 - val_loss: 0.9049\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8339 - val_loss: 0.9049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[train_ratings['user_id'], train_ratings['movie_id']],\n",
    "                    y=train_ratings['rating'], epochs=500,\n",
    "                    validation_data=([test_ratings['user_id'], test_ratings['movie_id'] ],\n",
    "                                     test_ratings['rating']),\n",
    "                    verbose=1, batch_size=train_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings = {\n",
    "    'user_id': model.get_layer('user_embedding').weights[0].numpy(), # U (943, 30)\n",
    "    'movie_id': model.get_layer('movie_embedding').weights[0].numpy() # V (1682, 30)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 943 entries, 0 to 942\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   user_id     943 non-null    int64 \n",
      " 1   age         943 non-null    int64 \n",
      " 2   sex         943 non-null    object\n",
      " 3   occupation  943 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 29.6+ KB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train loss', 'validation loss'])\n",
    "plt.ylim([0,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>939</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>940</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>942</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age sex     occupation\n",
       "938      938   26   F        student\n",
       "939      939   32   M  administrator\n",
       "940      940   20   M        student\n",
       "941      941   48   F      librarian\n",
       "942      942   22   M        student"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOT = 'dot'\n",
    "COSINE = 'cosine'\n",
    "def compute_scores(query_embedding, item_embeddings, measure=DOT):\n",
    "  \"\"\"Computes the scores of the candidates given a query.\n",
    "  Args:\n",
    "    query_embedding: a vector of shape [k], representing the query embedding.\n",
    "    item_embeddings: a matrix of shape [N, k], such that row i is the embedding\n",
    "      of item i.\n",
    "    measure: a string specifying the similarity measure to be used. Can be\n",
    "      either DOT or COSINE.\n",
    "  Returns:\n",
    "    scores: a vector of shape [N], such that scores[i] is the score of item i.\n",
    "  \"\"\"\n",
    "  u = query_embedding\n",
    "  V = item_embeddings\n",
    "  if measure == COSINE:\n",
    "    V = V / np.linalg.norm(V, axis=1, keepdims=True)\n",
    "    u = u / np.linalg.norm(u)\n",
    "  scores = u.dot(V.T)\n",
    "  return scores\n",
    "USER_RATINGS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_recommendations(model, measure=DOT, exclude_rated=False, k=6, user_id=570):\n",
    "  if USER_RATINGS:\n",
    "    scores = compute_scores(\n",
    "        model.embeddings[\"user_id\"][user_id], model.embeddings[\"movie_id\"], measure)\n",
    "    score_key = measure + ' score'\n",
    "    df = pd.DataFrame({\n",
    "        score_key: list(scores),\n",
    "        'movie_id': movies['movie_id'],\n",
    "        'titles': movies['title'],\n",
    "        'genres': movies['all_genres'],\n",
    "    })\n",
    "    if exclude_rated:\n",
    "      # remove movies that are already rated\n",
    "      rated_movies = ratings[ratings.user_id == str(user_id)][\"movie_id\"].values\n",
    "      df = df[df.movie_id.apply(lambda movie_id: movie_id not in rated_movies)]\n",
    "    return (df.sort_values([score_key], ascending=False).head(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_neighbors(model, title_substring, measure=DOT, k=6):\n",
    "  # Search for movie ids that match the given substring.\n",
    "  ids =  movies[movies['title'].str.contains(title_substring)].index.values\n",
    "  titles = movies.iloc[ids]['title'].values\n",
    "  if len(titles) == 0:\n",
    "    raise ValueError(\"Found no movies with title %s\" % title_substring)\n",
    "  print(\"Nearest neighbors of : %s.\" % titles[0])\n",
    "  if len(titles) > 1:\n",
    "    print(\"[Found more than one matching movie. Other candidates: {}]\".format(\n",
    "        \", \".join(titles[1:])))\n",
    "  movie_id = ids[0]\n",
    "  scores = compute_scores(\n",
    "      model.embeddings[\"movie_id\"][movie_id], model.embeddings[\"movie_id\"],\n",
    "      measure)\n",
    "  score_key = measure + ' score'\n",
    "  df = pd.DataFrame({\n",
    "      score_key: list(scores),\n",
    "      'titles': movies['title'],\n",
    "      'genres': movies['all_genres']\n",
    "  })\n",
    "  return (df.sort_values([score_key], ascending=False).head(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot score</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>titles</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>4.678007</td>\n",
       "      <td>1535</td>\n",
       "      <td>Aiqing wansui (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>4.658752</td>\n",
       "      <td>813</td>\n",
       "      <td>Great Day in Harlem, A (1994)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>4.640284</td>\n",
       "      <td>1499</td>\n",
       "      <td>Santa with Muscles (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>4.594251</td>\n",
       "      <td>1466</td>\n",
       "      <td>Saint of Fort Washington, The (1993)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>4.593953</td>\n",
       "      <td>1598</td>\n",
       "      <td>Someone Else's America (1995)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>4.559278</td>\n",
       "      <td>1448</td>\n",
       "      <td>Pather Panchali (1955)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>4.479471</td>\n",
       "      <td>1397</td>\n",
       "      <td>Anna (1996)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>4.476431</td>\n",
       "      <td>1366</td>\n",
       "      <td>Faust (1994)</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>4.412363</td>\n",
       "      <td>1641</td>\n",
       "      <td>Some Mother's Son (1996)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4.408297</td>\n",
       "      <td>407</td>\n",
       "      <td>Close Shave, A (1995)</td>\n",
       "      <td>Animation-Comedy-Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dot score  movie_id                                titles  \\\n",
       "1535   4.678007      1535                  Aiqing wansui (1994)   \n",
       "813    4.658752       813         Great Day in Harlem, A (1994)   \n",
       "1499   4.640284      1499             Santa with Muscles (1996)   \n",
       "1466   4.594251      1466  Saint of Fort Washington, The (1993)   \n",
       "1598   4.593953      1598         Someone Else's America (1995)   \n",
       "1448   4.559278      1448                Pather Panchali (1955)   \n",
       "1397   4.479471      1397                           Anna (1996)   \n",
       "1366   4.476431      1366                          Faust (1994)   \n",
       "1641   4.412363      1641              Some Mother's Son (1996)   \n",
       "407    4.408297       407                 Close Shave, A (1995)   \n",
       "\n",
       "                         genres  \n",
       "1535                      Drama  \n",
       "813                 Documentary  \n",
       "1499                     Comedy  \n",
       "1466                      Drama  \n",
       "1598                      Drama  \n",
       "1448                      Drama  \n",
       "1397                      Drama  \n",
       "1366                  Animation  \n",
       "1641                      Drama  \n",
       "407   Animation-Comedy-Thriller  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recommendations(model, measure=DOT, k=10, user_id=942, exclude_rated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors of : Aladdin (1992).\n",
      "[Found more than one matching movie. Other candidates: Aladdin and the King of Thieves (1996)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dot score</th>\n",
       "      <th>titles</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>4.925954</td>\n",
       "      <td>Aiqing wansui (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>4.909720</td>\n",
       "      <td>Great Day in Harlem, A (1994)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>4.859949</td>\n",
       "      <td>Santa with Muscles (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>4.836514</td>\n",
       "      <td>Saint of Fort Washington, The (1993)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>4.834853</td>\n",
       "      <td>Someone Else's America (1995)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>4.804722</td>\n",
       "      <td>Pather Panchali (1955)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dot score                                titles       genres\n",
       "1535   4.925954                  Aiqing wansui (1994)        Drama\n",
       "813    4.909720         Great Day in Harlem, A (1994)  Documentary\n",
       "1499   4.859949             Santa with Muscles (1996)       Comedy\n",
       "1466   4.836514  Saint of Fort Washington, The (1993)        Drama\n",
       "1598   4.834853         Someone Else's America (1995)        Drama\n",
       "1448   4.804722                Pather Panchali (1955)        Drama"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_neighbors(model, \"Aladdin\", DOT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
